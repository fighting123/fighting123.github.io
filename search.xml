<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[github的gh-pages分支展示项目页面]]></title>
    <url>%2F2018%2F11%2F21%2Fgithub%E7%9A%84gh-pages%E5%88%86%E6%94%AF%E5%B1%95%E7%A4%BA%E9%A1%B9%E7%9B%AE%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[引言 github上的demo别人需要预览的时候都得clone下来运行才可以，不能外网访问，不利于demo效果的展示，其实将项目打包部署到GitHub Pages上就可以完美解决这个问题了。 用到的库 gh-pages 安装：yarn add gh-pages 部署过程创建项目仓库常规操作创建git仓库即可，可参考：https://blog.csdn.net/zoucanfa/article/details/77725839 在本地的项目文件下执行以下命令12345$ git init$ git add .$ git commit -m &apos;message&apos;$ git remote add origin &lt;url&gt;$ git push -u origin master 修改本地的package.json文件及相关配置由于React项目和Vue项目打包后的文件夹不一样，所以配置也稍稍有点不同 React： 12345&quot;homepage&quot;: &quot;https://fighting123.github.io/react_manage_system&quot;,&quot;scripts&quot;: &#123; + &quot;predeploy&quot;: &quot;npm run build&quot;, // 对应的deploy之前的钩子 + &quot;deploy&quot;: &quot;gh-pages -d build&quot; // deploy名字可以随意 &#125;, Vue: 1234&quot;scripts&quot;: &#123; + &quot;predeploy&quot;: &quot;npm run dist&quot;, // 或者yarn run dist + &quot;deploy&quot;: &quot;gh-pages -d dist&quot; &#125;, 并修改config/index.js: 123build: &#123; assetsPublicPath: &apos;&apos;&#125; 部署1yarn deploy // 或npm run deploy 部署过程真的感觉超级慢。。。 部署成功后，对应远程上就有新的gh-pages分支了，修改setting上的source为gh-pages分支，然后打开https://fighting123.github.io/react_manage_system即可看到对应的页面了。 总结总体来看，它的原理其实很简单，就是在当前项目仓库下自动创建一个名为gh-pages的分支，打包部署成功之后上传到这个分支的正好就是build内的静态文件，其实不怕麻烦的同学也可以不用这个库，自己一步步创建分支，上传build文件也可以实现同样的效果！ 遇到的问题及解决方法 运行yarn deploy过程中可能会报错 1fatal: A branch named &apos;gh-pages&apos; already exists. 官方文档上的解释是： 当处理gh-pages模块生成文件.cache，如果由于某些原因如密码错误等卡住则不会自动清理 解决办法： 运行 ~node_modules/gh-pages/bin/gh-pages-clean 或者直接删除项目下的 ~node_modules/gh-pages/.cache文件即可 运行yarn deploy过程中可能会报错 1fatal: The remote end hung up unexpectedly 官方文档上的解释是： 通过 HTTP 传输 POST 数据到远程系统上的最大缓冲字节数 。当请求大于这个缓冲大小时，HTTP/1.1 和 Transfer-Encoding: chunked 用来避免在本地创建过多的压缩文件。默认是 1MiB，适用于大多数的请求 解决办法： 1git config --global http.postbuffer 1048576000 运行yarn deploy过程中可能会报错 1could not read Username for &apos;https://github.com&apos;: No error **解决办法**： 修改.git下的config文件的url为https://用户名:密码@github.com/fighting123/react_manage_system.git即可 多个html文件的项目，如官网，用下面方法： 1234git symbolic-ref HEAD refs/heads/gh-pagesgit add -Agit commit -m &quot;描述&quot;git push origin gh-pages 参考文章： https://www.jianshu.com/p/9dcc6e68031e https://www.cnblogs.com/MuYunyun/p/6082359.html https://www.douban.com/note/668373438/ https://www.rails365.net/movies/react-ji-qiao-2-ba-react-ying-yong-bu-shu-dao-github-pages (把 react 应用部署到 GitHub Pages的视频)]]></content>
      <categories>
        <category>GitHub</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>gh-pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[js面试从闭包说起]]></title>
    <url>%2F2018%2F11%2F13%2Fjs%E9%9D%A2%E8%AF%95%E4%BB%8E%E9%97%AD%E5%8C%85%E8%AF%B4%E8%B5%B7%2F</url>
    <content type="text"><![CDATA[转自 https://segmentfault.com/p/1210000009077868/read 修订说明：发布《80% 应聘者都不及格的 JS 面试题》之后，全网阅读量超过 6W，在知乎、掘金、cnodejs都引发了很多讨论，还被多个前端微信公号和技术媒体转载。酝酿许久之后，笔者准备接下来撰写前端面试题系列文章，内容涵盖DOM、HTTP、浏览器、框架、编码、工程化等方面，一方面给求职同学梳理面试关键点、理解前端知识脉络，另一方面也给面试官同行做参考，如何设计由浅入深的面试题。本文是对第一篇文章的修订重发，读过的同学可以不用再读，感兴趣的可以看看追问1里面的增补，后续文章会在知乎、掘金、cnodejs 同步发布。 共 3599 字，读完需 7 分钟，速读需 3 分钟。写在前面，笔者在做面试官这 2 年多的时间内，面试了超过 200个前端工程师，惊讶的发现，超过 80%的候选人对下面这道跟闭包、定时器有关的面试题回答情况连及格都达不到。这究竟是怎样神奇的一道面试题？他考察了候选人的哪些能力？对正在读本文的你有什么启示？且听我慢慢道来。 不起眼的开始招聘前端工程师，尤其是中高级前端工程师，扎实的 JS 基础绝对是必要条件，基础不扎实的工程师在面对前端开发中的各种问题时大概率会束手无策。在考察候选人 JS 基础的时候，我经常会提供下面这段代码，然后让候选人分析它实际运行的结果： for (var i = 0; i &lt; 5; i++) { setTimeout(function() { console.log(new Date, i); }, 1000); } console.log(new Date, i); 这段代码很短，只有 7 行，我想，能读到这里的同学应该不需要我逐行解释这段代码在做什么吧。候选人面对这段代码时给出的结果也不尽相同，以下是典型的答案： A. 20% 的人会快速扫描代码，然后给出结果：0,1,2,3,4,5； B. 30% 的人会拿着代码逐行看，然后给出结果：5,0,1,2,3,4； C. 50% 的人会拿着代码仔细琢磨，然后给出结果：5,5,5,5,5,5；只要你对 JS 中同步和异步代码的区别、变量作用域、闭包等概念有正确的理解，就知道正确答案是 C，代码的实际输出是： 2017-03-18T00:43:45.873Z 5 2017-03-18T00:43:46.866Z 5 2017-03-18T00:43:46.868Z 5 2017-03-18T00:43:46.868Z 5 2017-03-18T00:43:46.868Z 5 2017-03-18T00:43:46.868Z 5 接下来我会追问：如果我们约定，用箭头表示其前后的两次输出之间有 1 秒的时间间隔，而逗号表示其前后的两次输出之间的时间间隔可以忽略，代码实际运行的结果该如何描述？会有下面两种答案： A. 60% 的人会描述为：5 -&gt; 5 -&gt; 5 -&gt; 5 -&gt; 5，即每个 5 之间都有 1 秒的时间间隔； B. 40% 的人会描述为：5 -&gt; 5,5,5,5,5，即第 1 个 5 直接输出，1 秒之后，输出 5 个 5；这就要求候选人对 JS 中的定时器工作机制非常熟悉，循环执行过程中，几乎同时设置了 5 个定时器，一般情况下，这些定时器都会在 1 秒之后触发，而循环完的输出是立即执行的，显而易见，正确的描述是 B。 如果到这里算是及格的话，100 个人参加面试只有 20 人能及格，读到这里的同学可以仔细思考，你及格了么？ 追问 1：闭包如果这道题仅仅是考察候选人对 JS 异步代码、变量作用域的理解，局限性未免太大，接下来我会追问，如果期望代码的输出变成：5 -&gt; 0,1,2,3,4，该怎么改造代码？熟悉闭包的同学很快能给出下面的解决办法： for (var i = 0; i &lt; 5; i++) { (function(j) { // j = i setTimeout(function() { console.log(new Date, j); }, 1000); })(i); } console.log(new Date, i); 巧妙的利用 IIFE（Immediately Invoked Function Expression：声明即执行的函数表达式）来解决闭包造成的问题，确实是不错的思路，但是初学者可能并不觉得这样的代码很好懂，至少笔者初入门的时候这里琢磨了一会儿才真正理解。 增补：如果有同学给出如下的解决方案，则说明他是一个仔细看API 文档的人，这种习惯会让他学习的时候少走弯路，具体代码如下： for (var i = 0; i &lt; 5; i++) { setTimeout(function(j) { console.log(new Date, j); }, 1000, i); } console.log(new Date, i); 有没有更符合直觉的做法？答案是有，我们只需要对循环体稍做手脚，让负责输出的那段代码能拿到每次循环的 i 值即可。该怎么做呢？利用 JS 中基本类型（Primitive Type）的参数传递是按值传递（Pass by Value）的特征，不难改造出下面的代码： var output = function (i) { setTimeout(function() { console.log(new Date, i); }, 1000); }; for (var i = 0; i &lt; 5; i++) { output(i); // 这里传过去的 i 值被复制了 } console.log(new Date, i); 能给出上述 2 种解决方案的候选人可以认为对 JS 基础的理解和运用是不错的，可以各加 10 分。当然实际面试中还有候选人给出如下的代码： for (let i = 0; i &lt; 5; i++) { setTimeout(function() { console.log(new Date, i); }, 1000); } console.log(new Date, i); 细心的同学会发现，这里只有个非常细微的变动，即使用 ES6 块级作用域（Block Scope）中的 let 替代了 var，但是代码在实际运行时会报错，因为最后那个输出使用的 i 在其所在的作用域中并不存在，i 只存在于循环内部。 能想到 ES6 特性的同学虽然没有答对，但是展示了自己对 ES6 的了解，可以加 5 分，继续进行下面的追问。 追问 2：ES6有经验的前端同学读到这里可能有些不耐烦了，扯了这么多，都是他知道的内容，先别着急，挑战的难度会继续增加。 接着上文继续追问：如果期望代码的输出变成 0 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 5，并且要求原有的代码块中的循环和两处 console.log 不变，该怎么改造代码？新的需求可以精确的描述为：代码执行时，立即输出 0，之后每隔 1 秒依次输出 1,2,3,4，循环结束后在大概第 5 秒的时候输出 5（这里使用大概，是为了避免钻牛角尖的同学陷进去，因为 JS 中的定时器触发时机有可能是不确定的，具体可参见 How Javascript Timers Work）。 看到这里，部分同学会给出下面的可行解： for (var i = 0; i &lt; 5; i++) { (function(j) { setTimeout(function() { console.log(new Date, j); }, 1000 * j); // 这里修改 0~4 的定时器时间 })(i); } setTimeout(function() { // 这里增加定时器，超时设置为 5 秒 console.log(new Date, i); }, 1000 * i); 不得不承认，这种做法虽粗暴有效，但是不算是能额外加分的方案。如果把这次的需求抽象为：在系列异步操作完成（每次循环都产生了 1 个异步操作）之后，再做其他的事情，代码该怎么组织？聪明的你是不是想起了什么？对，就是 Promise。 可能有的同学会问，不就是在控制台输出几个数字么？至于这样杀鸡用牛刀？你要知道，面试官真正想考察的是候选人是否具备某种能力和素质，因为在现代的前端开发中，处理异步的代码随处可见，熟悉和掌握异步操作的流程控制是成为合格开发者的基本功。 顺着下来，不难给出基于 Promise 的解决方案（既然 Promise 是 ES6 中的新特性，我们的新代码使用 ES6 编写是不是会更好？如果你这么写了，大概率会让面试官心生好感）： const tasks = []; for (var i = 0; i &lt; 5; i++) { // 这里 i 的声明不能改成 let，如果要改该怎么做？ ((j) =&gt; { tasks.push(new Promise((resolve) =&gt; { setTimeout(() =&gt; { console.log(new Date, j); resolve(); // 这里一定要 resolve，否则代码不会按预期 work }, 1000 * j); // 定时器的超时时间逐步增加 })); })(i); } Promise.all(tasks).then(() =&gt; { setTimeout(() =&gt; { console.log(new Date, i); }, 1000); // 注意这里只需要把超时设置为 1 秒 }); 相比而言，笔者更倾向于下面这样看起来更简洁的代码，要知道编程风格也是很多面试官重点考察的点，代码阅读时的颗粒度更小，模块化更好，无疑会是加分点。 const tasks = []; // 这里存放异步操作的 Promise const output = (i) =&gt; new Promise((resolve) =&gt; { setTimeout(() =&gt; { console.log(new Date, i); resolve(); }, 1000 * i); }); // 生成全部的异步操作 for (var i = 0; i &lt; 5; i++) { tasks.push(output(i)); } // 异步操作完成之后，输出最后的 i Promise.all(tasks).then(() =&gt; { setTimeout(() =&gt; { console.log(new Date, i); }, 1000); }); 读到这里的同学，恭喜你，你下次面试遇到类似的问题，至少能拿到 80 分。 我们都知道使用 Promise 处理异步代码比回调机制让代码可读性更高，但是使用 Promise 的问题也很明显，即如果没有处理 Promise 的 reject，会导致错误被丢进黑洞，好在新版的 Chrome 和 Node 7.x 能对未处理的异常给出 Unhandled Rejection Warning，而排查这些错误还需要一些特别的技巧（浏览器、Node.js）。 追问 3：ES7既然你都看到这里了，那就再坚持 2 分钟，接下来的内容会让你明白你的坚持是值得的。 多数面试官在决定聘用某个候选人之前还需要考察另外一项重要能力，即技术自驱力，直白的说就是候选人像有内部的马达在驱动他，用漂亮的方式解决工程领域的问题，不断的跟随业务和技术变得越来越牛逼，究竟什么是牛逼？建议阅读程序人生的这篇剖析。 回到正题，既然 Promise 已经被拿下，如何使用 ES7 中的 async/await 特性来让这段代码变的更简洁？你是否能够根据自己目前掌握的知识给出答案？请在这里暂停 1 分钟，思考下。 下面是笔者给出的参考代码： // 模拟其他语言中的 sleep，实际上可以是任何异步操作 const sleep = (timeountMS) =&gt; new Promise((resolve) =&gt; { setTimeout(resolve, timeountMS); }); (async () =&gt; { // 声明即执行的 async 函数表达式 for (var i = 0; i &lt; 5; i++) { if (i &gt; 0) { await sleep(1000); } console.log(new Date, i); } await sleep(1000); console.log(new Date, i); })(); 总结感谢你花时间读到这里，相信你收获的不仅仅是用 JS 精确控制数字输出的各种技巧，而是各种技巧背后的知识，从宏观层面，则要明确合格前端工程师应该具备的特征：扎实的语言基础、与时俱进的能力、强大的技术自驱力，后续文章见。]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>js面试</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue单页面：当前页面刷新或跳转时提示保存]]></title>
    <url>%2F2018%2F11%2F01%2Fvue%E5%8D%95%E9%A1%B5%E9%9D%A2%EF%BC%9A%E5%BD%93%E5%89%8D%E9%A1%B5%E9%9D%A2%E5%88%B7%E6%96%B0%E6%88%96%E8%B7%B3%E8%BD%AC%E6%97%B6%E6%8F%90%E7%A4%BA%E4%BF%9D%E5%AD%98%2F</url>
    <content type="text"><![CDATA[前言 最近公司vue项目中有一个需求，需要在当前页面刷新或跳转时提示保存并可取消刷新，以防止填写的表单内容丢失。刚开始思考觉得很简单，直接在Router的钩子中判断就好了，但是会发现还有新的问题存在，浏览器刷新和当前页面关闭的时候无法监听，最终用window.onbeforeunload成功解决，所以用这篇文章简单记录下整个解决过程。 vue-Router的钩子：路由钩子可以分为全局的，单个路由独享的以及组件级别的，解决上述需求只用到了组件级别的路由钩子，所以本文只介绍组件级别的路由钩子，全局的和单个路由独享的路由钩子有需要的同学可以去vue-router官网查看介绍： 组件级别路由钩子分为三种： beforeRouteEnter：当成功获取并能进入路由(在渲染该组件的对应路由被 confirm 前) beforeRouteUpdate：在当前路由改变，但是该组件被复用时调用 beforeRouteLeave：导航离开该组件的对应路由时调用 具体的介绍和写法如下：1234567891011121314151617181920212223242526272829303132const Foo = &#123; template: `...`, beforeRouteEnter (to, from, next) &#123; // 在渲染该组件的对应路由被 confirm 前调用 // 不！能！获取组件实例 `this` // 因为当守卫执行前，组件实例还没被创建 // 可以通过传一个回调给 next来访问组件实例 next(vm =&gt; &#123; // 通过 `vm` 访问组件实例 &#125;) &#125;, beforeRouteUpdate (to, from, next) &#123; // 在当前路由改变，但是该组件被复用时调用 // 举例来说，对于一个带有动态参数的路径 /foo/:id，在 /foo/1 和 /foo/2 之间跳转的时候， // 由于会渲染同样的 Foo 组件，因此组件实例会被复用。而这个钩子就会在这个情况下被调用。 // 可以访问组件实例 `this` // 不支持传递回调(因为this实例已经创建可以获取到，所以没必要) next() &#125;, beforeRouteLeave (to, from, next) &#123; // 导航离开该组件的对应路由时调用 // 可以访问组件实例 `this` // 该导航可以通过 next(false) 来取消。 const answer = window.confirm(&apos;Do you really want to leave? you have unsaved changes!&apos;) if (answer) &#123; next() &#125; else &#123; // 不支持传递回调(因为this实例已经创建可以获取到，所以没必要) next(false) &#125; &#125;&#125; 注意：在刷新当前页面时候，beforeRouteLeave不会触发，它只在进入到其他页面时候才会触发，但是beforeRouteEnter会在刷新的时候触发。 通过beforeRouteLeave这个路由钩子，我们就可以在用户要离开此页面时候进行提示了！ 12345678beforeRouteLeave (to, from, next) &#123; const answer = window.confirm(&apos;当前页面数据未保存，确定要离开![image](http://note.youdao.com/favicon.ico)？&apos;) if (answer) &#123; next() &#125; else &#123; next(false) &#125; &#125; 显示的提示框如下： 监听浏览器的刷新、页面关闭事件但是，这个时候就实现了我们最终的需求了么？并没有，还有一步：用window.onbeforeunload监听浏览器的刷新事件，当然为了防止从当前单页面跳到其他页面之后，在刷新所在新的页面还会触发window上的onbeforeunload的问题，我们不仅要及时的添加onbeforeunload事件，更要及时删除此事件，下面有两种解决方法可供选择： 通过判断它的路由是否是当前需要添加禁止刷新的页面 123456789101112131415mounted() &#123; window.onbeforeunload = function (e) &#123; if(_this.$route.fullPath ==&quot;/layout/add&quot;)&#123; e = e || window.event; // 兼容IE8和Firefox 4之前的版本 if (e) &#123; e.returnValue = &apos;关闭提示&apos;; &#125; // Chrome, Safari, Firefox 4+, Opera 12+ , IE 9+ return &apos;关闭提示&apos;; &#125;else&#123; window.onbeforeunload =null &#125;&#125;&#125;; 在destory或者beforeDestory的生命周期中直接将onbeforeunload事件置空1234567891011121314mounted() &#123; window.onbeforeunload = function (e) &#123; e = e || window.event; // 兼容IE8和Firefox 4之前的版本 if (e) &#123; e.returnValue = &apos;关闭提示&apos;; &#125; // Chrome, Safari, Firefox 4+, Opera 12+ , IE 9+ return &apos;关闭提示&apos;; &#125;&#125;;destroyed() &#123; window.onbeforeunload = null &#125; 显示的提示框如下： 总结最终，在beforeRouteLeave和onbeforeunload的共同作用下，这个刷新、跳转或者关闭等情况下需要提示保存的需求完美解决！但是，还有一点点小遗憾，就是onbeforeunload中弹框的自定义提示语设置始终无法生效，大家要是有更加合适的处理办法，欢迎多多交流指正！]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>Vue</tag>
        <tag>Vue-Router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识react， 并简单与vue对比]]></title>
    <url>%2F2018%2F08%2F01%2F%E8%AE%A4%E8%AF%86react%EF%BC%8C-%E5%B9%B6%E7%AE%80%E5%8D%95%E4%B8%8Evue%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[应用场景： 负责场景下的高性能 重用组件库，组件组合 中文官网：https://reactjs.org.cn/doc/installation.html 特点： 声明式编码(不需要关心如何实现，只需要关注在哪里做什么) 组件化编码 高效的DOM Diff，最小化页面重绘 单向数据流 创建一个新的app：12345npm install -g create-react-appcreate-react-app my-appcd my-appnpm start 使用 Yarn 安装 React： 12yarn inityarn add react react-dom 使用npm来安装 React： 12npm initnpm install --save react react-dom 使用antd：根据这个搭建环境: https://ant.design/docs/react/use-with-create-react-app-cn react和vue一样： 结合各自的生态库构成MVC框架 react和vue不一样： vue双向绑定，react单项绑定 react每次安装新包需要重新npm install，否则会报错： 1&apos;react-app-rewired&apos; 不是内部或外部命令，也不是可运行的程序或批处理文件。 生态库： vue: Vue + Vue-Router + VueX + Axios + Babel + Webpack react: React + React-Router + Redux + Axios + Babel + Webpack react-router:线上学习react地址：https://reacttraining.com/react-router/web/example/auth-workflow注：如果要每个路由都是新的页面不包含上个页面，就添加exact hashHistory 通过 hash 进行对应。好处是简单易用，不用多余设定。 browserHistory 适用于服务器端渲染，但需要设定服务器端避免处理错误。注意的是若使用 Webpack 开发用,服务器需加上 –history-api-fallback $ webpack-dev-server –inline –content-base . –history-api-fallback createMemoryHistory主要用于服务器渲染，使用上会建立一个存在记忆体的 history 物件，不会修改浏览器的网址位置。 const history = createMemoryHistory(location)]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>react</tag>
        <tag>react与vue对比</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Puppeteer(操纵Chrome的API)]]></title>
    <url>%2F2018%2F07%2F15%2FPuppeteer-%E6%93%8D%E7%BA%B5Chrome%E7%9A%84API%2F</url>
    <content type="text"><![CDATA[介绍：英文版官方文档：https://github.com/GoogleChrome/puppeteer/blob/master/docs/api.md#puppeteerlaunchoptions Puppeteer是一组用来操纵Chrome的API，默认headless也就是无UI的chrome，也可以配置为有UI，和PhantomJS类似，但是比他更有前景，可以实现爬虫，性能分析，自动化测试等功能。 适用情况简单地通过get或post就能搞定的就不需要puppeteer了。 调接口获取不到的或者涉及请求加密的用puppeteer。 安装最近蓝灯又被封了，上不了谷歌，puppeter又依赖Chromium/Chrome59+，只能折中啦–用puppeteer-cn代替puppeteer，这个包会先去检测本地Chrome版本是否大于59，再决定是否通过一个国内源下载Chromium，具体使用几乎和puppeteer一致。 puppeteer下载Chromium的默认路径是google服务器，GFW的原因可能会下载失败。puppeteer-cn还是依赖了puppeteer的，只是改写了其中的launch方法，并主动检测本地chrome是否符合headless条件，不符合会使用国内源安装Chromium。 1npm install puppeteer-cn --save 怎么发现这样还是报错呢，还是cnpm靠谱啊,可以直接下载puppeteer-cn：12npm install -g cnpm --registry=https://registry.npm.taobao.orgcnpm i puppeteer 或者更换国内Chromium源（暂时没有测试）：12PUPPETEER_DOWNLOAD_HOST=https://storage.googleapis.com.cnpmjs.orgnpm i puppeteer 每次新建一个项目都要重新下载chromium，很不方便，其实可以把它下载到本地，每次都在puppeteer.launch({})中指定executablePath的位置，但是一定要注意chromium的版本是r543305，这有这个版本可以，否则会报错，具体在自己新建文件中的配置代码如下（不好找对应版本的话，可以第一次cnpm安装后在对应的路径下找到自带的chromium，这个版本肯定是正确的，将它提出来放到本地某个文件夹下即可）：123456789101112const browser = await (puppeteer.launch(&#123; // 若是手动下载的chromium需要指定chromium地址, 默认引用地址为 /项目目录/node_modules/puppeteer/.local-chromium/ executablePath: &apos;D:/app/chromium/chrome-win32/chrome.exe&apos;, //设置超时时间 timeout: 15000, //如果是访问https页面 此属性会忽略https错误 ignoreHTTPSErrors: true, // 打开开发者工具, 当此值为true时, headless总为false devtools: false, // 关闭headless模式, 会打开浏览器 headless: false &#125;));]]></content>
      <categories>
        <category>Node.js</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node模拟登录segmentfault]]></title>
    <url>%2F2018%2F07%2F10%2Fnode%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95segmentfault%2F</url>
    <content type="text"><![CDATA[前言前段时间看的爬虫都是不需要登录直接爬取数据，这回就试试爬取需要登录的网站信息吧，说干就干，直接就拿segmentfault做为目标！ 一、爬虫所需模块 superagent async二、分析我们首先用chrome或者其他浏览器打开segmentfault的主页，找到它的登录接口，点击登录接口，记得把Preserve log勾上，否则跳转之后找不到接口，如图（重要信息打了马赛克）： 显而易见这是一个post请求，三个参数分别是用户名、密码、和是否记住密码的标记。 获取Cookie里的PHPSESSID仔细看请求头header里的cookie，在请求发送的时候就已经有了，我们直接把整个请求头拿过来，就直接用图中的接口和header登录，逐一删除cookie中的项，测试登录结果，最终发现只有PHPSESSID是必须的。这个PHPSESSID如何获取呢？我们可以在登录之前先访问segmentfault主页，将返回的cookie拿到，再在登录的时候加上这个cookie即可。获取cookie的代码如下： 123456789(cb) =&gt; &#123; superagent .get(&apos;https://segmentfault.com&apos;) .end((err, res) =&gt; &#123; if (err) console.log(err) cookie = res.headers[&apos;set-cookie&apos;].join(&apos;,&apos;).split(&apos;;&apos;)[0] // 获取PHPSESSID cb(null) &#125;) &#125; 获取Query String Paramsters里的 _ 参数还有一个参数需要注意：接口中的Query String Paramsters的_参数，那么这个参数是怎么来的呢？在返回的response的header里寻找并没有找到它的踪迹，所以猜想它应该是隐藏在源码里，我们直接在chrome控制台的source下全局搜索_=（source顶部右键选择search in all files即可出现全局搜索框）,逐一排查可能性： 排查过程中发现箭头所指的ajaxSend函数好像和我们需要的有关系：它紧邻的下面的delegate函数内容应该就是登陆有关的内容，通过/api/user/?do=login和submit等就可以清楚的看出，这个函数中的url是从n.attr(&#39;action&#39;)拿到的，猜测这个n.__肯定和请求中的Query String参数脱不了关系。正好这个ajaxSend函数中就有n.__,也正好验证了我们刚才的推测，分析这行代码：1n.url.indexOf(&quot;?&quot;) === -1 ? n.url = n.url + &quot;?_=&quot; + i._ : n.url = n.url + &quot;&amp;_=&quot; + i._ n.url默认是n.url + &quot;?_=&quot; + i._ ，那么这个i.__应该就是最终boss，就在这个文件中找到定义i的代码，如上图箭头所指，继续全局搜索SF.token,最终在index.html中找了生成它的代码，包含在一个script中，如图： 找到来源就简单了，我们仍然是在登录直接先访问主页，将整个主页的html代码拿到，然后将这个script的内容取出来不就行了，哈哈，好开心~获取script的代码如下： 12345678910var cheerio = require(&apos;cheerio&apos;)function getRandom(s) &#123; let $ = cheerio.load(s) let script = $(&apos;script&apos;).eq(8).html() let fn = new Function(&apos;window&apos;, script + &apos;;return window.SF.token&apos;) let token = fn(&#123;&#125;) $ = null return token&#125;exports.getRandom = getRandom 到这里，登录就算完成了一大半了，接下来就是简单的用superagent调用接口啦，这里的请求头出了cookie的其他部分也是必须要设置的，可以直接从浏览器上copy下来，代码如下： 123456789101112131415161718192021222324252627282930313233343536(cb) =&gt; &#123; const username = process.argv[2] const password = process.argv[3] console.log(cookie) console.log(random) let header = &#123; &apos;accept&apos;: &apos;*/*&apos;, &apos;accept-encoding&apos;: &apos;gzip, deflate, br&apos;, &apos;accept-language&apos;: &apos;zh-CN,zh;q=0.9&apos;, &apos;content-length&apos;: &apos;47&apos;, &apos;content-type&apos;: &apos;application/x-www-form-urlencoded; charset=UTF-8&apos;, &apos;cookie&apos;: `PHPSESSID=$&#123;cookie&#125;;`, &apos;origin&apos;: &apos;https://segmentfault.com&apos;, &apos;referer&apos;: &apos;https://segmentfault.com/&apos;, &apos;user-agent&apos;: &apos;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&apos;, &apos;x-requested-with&apos;: &apos;XMLHttpRequest&apos; &#125; superagent .post(`https://segmentfault.com/api/user/login`) .query(&#123;&apos;_&apos;: random&#125;) .set(header) .type(&apos;form&apos;) .send(&#123; username: username, password: password, remember: 1 &#125;) .end(function(err, res) &#123; if (err) &#123; console.log(err.status); &#125; else &#123; console.log(&apos;返回状态码： &apos; + res.status) cb(null) &#125; &#125;) &#125;, 终于返回200了，美滋滋，然后我们继续~比如我我想用代码修改个人主页的个人描述内容，首先我们先找到相关接口，如图： 这个post请求的参数description就是个人描述的所填写的新的内容，我们直接用superagent调用这个接口123456789101112131415161718192021(cb) =&gt; &#123; superagent // 编辑右上角个人说明 .post(&apos;https://segmentfault.com/api/user/homepage/description/edit&apos;) .query(&#123;&apos;_&apos;: random&#125;) .set(header) .type(&apos;form&apos;) .send(&#123; description: &apos;努力coding的小喵~~~&apos; &#125;) .end((err, res) =&gt; &#123; if(err) throw err let result = JSON.parse(res.text) if (result.status === 0) &#123; console.log(&apos;编辑成功&apos;) &#125; else &#123; console.log(&apos;编辑失败：&apos; + result.data) &#125; &#125;) cb(null, 1) &#125; 返回状态码200，然后直接去浏览上的主页刷新下，可以看到个人描述的内容已经成功更新了！ 总结 打开segmentfault主页并登陆，找到登录请求的接口并分析 用node登录之前，先请求主页接口，目的是拿到PHPSESSID和源代码中的生成Query String的函数 带着这两个参数去请求登录接口，记得设置请求头 登录成功之后就可以干任何你想干的事情啦 整个登录过程耗费了很久的时间，有空就研究这个Query String的来源，好不容易登录成功想干点事情，又没注意到设置请求头，以为是sf_remember参数的问题，又折腾了许久，还好，最终总算是成功了！感谢自己的不放弃~ 源码github地址：https://github.com/fighting123/node_login_segmentfault.git]]></content>
      <categories>
        <category>Node.js</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[拉勾网爬虫并导出excel]]></title>
    <url>%2F2018%2F07%2F05%2F%E6%8B%89%E5%8B%BE%E7%BD%91%E7%88%AC%E8%99%AB%E5%B9%B6%E5%AF%BC%E5%87%BAexcel%2F</url>
    <content type="text"><![CDATA[前言 之前断断续续学习了node.js，今天就拿拉勾网练练手，顺便通过数据了解了解最近的招聘行情哈！node方面算是萌新一个吧，希望可以和大家共同学习和进步。 一、概要我们首先需要明确具体的需求： 可以通过node index 城市 职位来爬取相关信息 也可以输入node index start直接爬取我们预定义好的城市和职位数组，循环爬取不同城市的不同职位信息 将最终爬取的结果存储在本地的./data目录下 生成对应的excel文件，并存储到本地 二、爬虫用到的相关模块 fs: 用于对系统文件及目录进行读写操作 async：流程控制 superagent：客户端请求代理模块 node-xlsx：将一定格式的文件导出为excel 三、爬虫主要步骤：初始化项目新建项目目录 在合适的磁盘目录下创建项目目录 node-crwl-lagou 初始化项目 进入node-crwl-lagou文件夹下 执行npm init，初始化package.json文件 安装依赖包 npm install async npm install superagent npm install node-xlsx 命令行输入的处理对于在命令行输入的内容，可以用process.argv来获取，他会返回个数组，数组的每一项就是用户输入的内容。区分node index 地域 职位和node index start两种输入，最简单的就是判断process.argv的长度，长度为四的话，就直接调用爬虫主程序爬取数据，长度为三的话，我们就需要通过预定义的城市和职位数组来拼凑url了，然后利用async.mapSeries循环调用主程序。关于命令分析的主页代码如下： 1234567891011121314151617181920212223if (process.argv.length === 4) &#123; let args = process.argv console.log(&apos;准备开始请求&apos; + args[2] + &apos;的&apos; + args[3] + &apos;职位数据&apos;); requsetCrwl.controlRequest(args[2], args[3])&#125; else if (process.argv.length === 3 &amp;&amp; process.argv[2] === &apos;start&apos;) &#123; let arr = [] for (let i = 0; i &lt; defaultArgv.city.length; i++) &#123; for (let j = 0; j &lt; defaultArgv.position.length; j++) &#123; let obj = &#123;&#125; obj.city = defaultArgv.city[i] obj.position = defaultArgv.position[j] arr.push(obj) &#125; &#125; async.mapSeries(arr, function (item, callback) &#123; console.log(&apos;准备开始请求&apos; + item.city + &apos;的&apos; + item.position + &apos;职位数据&apos;); requsetCrwl.controlRequest(item.city, item.position, callback) &#125;, function (err) &#123; if (err) throw err &#125;)&#125; else &#123; console.log(&apos;请正确输入要爬取的城市和职位，正确格式为：&quot;node index 城市 关键词&quot; 或 &quot;node index start&quot; 例如：&quot;node index 北京 php&quot; 或&quot;node index start&quot;&apos;)&#125; 预定义好的城市和职位数组如下： 1234&#123; &quot;city&quot;: [&quot;北京&quot;,&quot;上海&quot;,&quot;广州&quot;,&quot;深圳&quot;,&quot;杭州&quot;,&quot;南京&quot;,&quot;成都&quot;,&quot;西安&quot;,&quot;武汉&quot;,&quot;重庆&quot;], &quot;position&quot;: [&quot;前端&quot;,&quot;java&quot;,&quot;php&quot;,&quot;ios&quot;,&quot;android&quot;,&quot;c++&quot;,&quot;python&quot;,&quot;.NET&quot;]&#125; 接下来就是爬虫主程序部分的分析了。 分析页面，找到请求地址首先我们打开拉勾网首页，输入查询信息（比如node），然后查看控制台，找到相关的请求，如图： 这个post请求https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false就是我们所需要的，通过三个请求参数来获取不同的数据，简单的分析就可得知：参数first是标注当前是否是第一页，true为是，false为否；参数pn是当前的页码；参数kd是查询输入的内容。 通过superagent请求数据首先需要明确得是，整个程序是异步的，我们需要用async.series来依次调用。查看分析返回的response： 可以看到content.positionResult.totalCount就是我们所需要的总页数我们用superagent直接调用post请求，控制台会提示如下信息： {&apos;success&apos;: False, &apos;msg&apos;: &apos;您操作太频繁,请稍后再访问&apos;, &apos;clientIp&apos;: &apos;122.xxx.xxx.xxx&apos;} 这其实是反爬虫策略之一，我们只需要给其添加一个请求头即可，请求头的获取方式很简单，如下： ] 然后在用superagent调用post请求，主要代码如下： 12345678910111213141516171819202122// 先获取总页数 (cb) =&gt; &#123; superagent .post(`https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false&amp;city=$&#123;city&#125;&amp;kd=$&#123;position&#125;&amp;pn=1`) .send(&#123; &apos;pn&apos;: 1, &apos;kd&apos;: position, &apos;first&apos;: true &#125;) .set(options.options) .end((err, res) =&gt; &#123; if (err) throw err // console.log(res.text) let resObj = JSON.parse(res.text) if (resObj.success === true) &#123; totalPage = resObj.content.positionResult.totalCount; cb(null, totalPage); &#125; else &#123; console.log(`获取数据失败:$&#123;res.text&#125;&#125;`) &#125; &#125;) &#125;, 拿到总页数后，我们就可以通过总页数/15获取到pn参数，循环生成所有url并存入urls中： 1234567(cb) =&gt; &#123; for (let i=0;Math.ceil(i&lt;totalPage/15);i++) &#123; urls.push(`https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false&amp;city=$&#123;city&#125;&amp;kd=$&#123;position&#125;&amp;pn=$&#123;i&#125;`) &#125; console.log(`$&#123;city&#125;的$&#123;position&#125;职位共$&#123;totalPage&#125;条数据，$&#123;urls.length&#125;页`); cb(null, urls); &#125;, 有了所有的url，在想爬到所有的数据就不是难事了，继续用superagent的post方法循环请求所有的url，每一次获取到数据后，在data目录下创建json文件，将返回的数据写入。这里看似简单，但是有两点需要注意： 为了防止并发请求太多而导致被封IP：循环url时候需要使用async.mapLimit方法控制并发为3， 每次请求完都要过两秒在发送下一次的请求 在async.mapLimit的第四个参数中，需要通过判断调用主函数的第三个参数是否存在来区分一下是那种命令输入，因为对于node index start这个命令，我们使用得是async.mapSeries，每次调用主函数都传递了(city, position, callback)，所以如果是node index start的话，需要在每次获取数据完后将null传递回去，否则无法进行下一次循环 主要代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 控制并发为3 (cb) =&gt; &#123; async.mapLimit(urls, 3, (url, callback) =&gt; &#123; num++; let page = url.split(&apos;&amp;&apos;)[3].split(&apos;=&apos;)[1]; superagent .post(url) .send(&#123; &apos;pn&apos;: totalPage, &apos;kd&apos;: position, &apos;first&apos;: false &#125;) .set(options.options) .end((err, res) =&gt; &#123; if (err) throw err let resObj = JSON.parse(res.text) if (resObj.success === true) &#123; console.log(`正在抓取第$&#123;page&#125;页，当前并发数量：$&#123;num&#125;`); if (!fs.existsSync(&apos;./data&apos;)) &#123; fs.mkdirSync(&apos;./data&apos;); &#125; // 将数据以.json格式储存在data文件夹下 fs.writeFile(`./data/$&#123;city&#125;_$&#123;position&#125;_$&#123;page&#125;.json`, res.text, (err) =&gt; &#123; if (err) throw err; // 写入数据完成后，两秒后再发送下一次请求 setTimeout(() =&gt; &#123; num--; console.log(`第$&#123;page&#125;页写入成功`); callback(null, &apos;success&apos;); &#125;, 2000); &#125;); &#125; &#125;) &#125;, (err, result) =&gt; &#123; if (err) throw err; // 这个arguments是调用controlRequest函数的参数，可以区分是那种爬取（循环还是单个） if (arguments[2]) &#123; ok = 1; &#125; cb(null, ok) &#125;) &#125;, () =&gt; &#123; if (ok) &#123; setTimeout(function () &#123; console.log(`$&#123;city&#125;的$&#123;position&#125;数据请求完成`); indexCallback(null); &#125;, 5000); &#125; else &#123; console.log(`$&#123;city&#125;的$&#123;position&#125;数据请求完成`); &#125; // exportExcel.exportExcel() // 导出为excel &#125; 导出的json文件如下： json文件导出为excel将json文件导出为excel有多种方式，我使用的是node-xlsx这个node包，这个包需要将数据按照固定的格式传入，然后导出即可，所以我们首先做的就是先拼出其所需的数据格式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869function exportExcel() &#123; let list = fs.readdirSync(&apos;./data&apos;) let dataArr = [] list.forEach((item, index) =&gt; &#123; let path = `./data/$&#123;item&#125;` let obj = fs.readFileSync(path, &apos;utf-8&apos;) let content = JSON.parse(obj).content.positionResult.result let arr = [[&apos;companyFullName&apos;, &apos;createTime&apos;, &apos;workYear&apos;, &apos;education&apos;, &apos;city&apos;, &apos;positionName&apos;, &apos;positionAdvantage&apos;, &apos;companyLabelList&apos;, &apos;salary&apos;]] content.forEach((contentItem) =&gt; &#123; arr.push([contentItem.companyFullName, contentItem.phone, contentItem.workYear, contentItem.education, contentItem.city, contentItem.positionName, contentItem.positionAdvantage, contentItem.companyLabelList.join(&apos;,&apos;), contentItem.salary]) &#125;) dataArr[index] = &#123; data: arr, name: path.split(&apos;./data/&apos;)[1] // 名字不能包含 \ / ? * [ ] &#125; &#125;)// 数据格式// var data = [// &#123;// name : &apos;sheet1&apos;,// data : [// [// &apos;ID&apos;,// &apos;Name&apos;,// &apos;Score&apos;// ],// [// &apos;1&apos;,// &apos;Michael&apos;,// &apos;99&apos;//// ],// [// &apos;2&apos;,// &apos;Jordan&apos;,// &apos;98&apos;// ]// ]// &#125;,// &#123;// name : &apos;sheet2&apos;,// data : [// [// &apos;AA&apos;,// &apos;BB&apos;// ],// [// &apos;23&apos;,// &apos;24&apos;// ]// ]// &#125;// ]// 写xlsx var buffer = xlsx.build(dataArr) fs.writeFile(&apos;./result.xlsx&apos;, buffer, function (err) &#123; if (err) throw err; console.log(&apos;Write to xls has finished&apos;);// 读xlsx// var obj = xlsx.parse(&quot;./&quot; + &quot;resut.xls&quot;);// console.log(JSON.stringify(obj)); &#125; );&#125; 导出的excel文件如下，每一页的数据都是一个sheet，比较清晰明了： 我们可以很清楚的从中看出目前西安.net的招聘情况，之后也可以考虑用更形象的图表方式展示爬到的数据，应该会更加直观！ 总结其实整个爬虫过程并不复杂，注意就是注意的小点很多，比如async的各个方法的使用以及导出设置header等，总之，也是收获满满哒！ 源码gitbug地址： https://github.com/fighting123/node_crwl_lagou]]></content>
      <categories>
        <category>Node.js</category>
      </categories>
      <tags>
        <tag>node</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[logger4js日志中间件]]></title>
    <url>%2F2018%2F04%2F18%2Flogger4js%E6%97%A5%E5%BF%97%E4%B8%AD%E9%97%B4%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[周报管理系统的日志模块本来是简单地console.log()出一些请求信息，但是并不能长时间保存，也不方便查看问题，但是logger4js这个中间件完美的实现了我要的功能。 先贴出他的以及两篇有关配置的参考文章： github地址：https://github.com/log4js-node/log4js-node/ nodejs Log4js v1.x配置使用(主要是参考目录结构)：https://www.jianshu.com/p/6b816c609669 nodejs Log4js v2.x配置使用：https://blog.csdn.net/llzkkk12/article/details/78165779 使用步骤： 1.安装1npm install log4js –save 2.配置新建log_config.js，这里是他的相关配置，注意categories的level，配置日志的输出级别,共ALL &lt; TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR &lt; FATAL &lt; MARK &lt; OFF八个级别,default level is OFF只有大于等于日志配置级别的信息才能输出出来，可以通过category来有效的控制日志输出级别 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748var path = require(&apos;path&apos;);var fs = require(&apos;fs&apos;);//日志根目录var baseLogPath = path.resolve(__dirname, &apos;../logs&apos;)//错误日志目录var errorPath = &quot;/error&quot;;//错误日志文件名var errorFileName = &quot;error&quot;;//错误日志输出完整路径var errorLogPath = baseLogPath + errorPath + &quot;/&quot; + errorFileName;//响应日志目录var responsePath = &quot;/response&quot;;//响应日志文件名var responseFileName = &quot;response&quot;;//响应日志输出完整路径var responseLogPath = baseLogPath + responsePath + &quot;/&quot; + responseFileName;let log_config_obj = &#123; appenders: &#123; out: &#123; type: &apos;console&apos; &#125;, errorLogger: &#123; &quot;type&quot;: &quot;dateFile&quot;, //日志类型 &quot;filename&quot;: errorLogPath, //日志输出位置 &quot;alwaysIncludePattern&quot;: true, //是否总是有后缀名 &quot;pattern&quot;: &quot;-yyyy-MM-dd-hh.log&quot;, //后缀，每小时创建一个新的日志文件 &quot;path&quot;: errorPath //自定义属性，错误日志的根目录 &#125;, resLogger: &#123; &quot;type&quot;: &quot;dateFile&quot;, &quot;filename&quot;: responseLogPath, &quot;alwaysIncludePattern&quot;: true, &quot;pattern&quot;: &quot;-yyyy-MM-dd-hh.log&quot;, &quot;path&quot;: responsePath &#125; &#125;, categories: &#123; default: &#123;appenders: [&apos;out&apos;], level: &apos;info&apos;&#125;, // 必须添加default，并且配置项都要写。所以添加了out errorLog: &#123; appenders: [&apos;errorLogger&apos;], level: &apos;error&apos; &#125;, resLog: &#123; appenders: [&apos;resLogger&apos;], level: &apos;info&apos; &#125; &#125;, baseLogPath: baseLogPath //logs根目录&#125;module.exports = log_config_obj 新建log_util.js文件，这里是日志保存的内容处理，代码太长，只有错误处理部分，请求处理部分同理： 1234567891011121314151617181920212223242526272829303132ar log4js = require(&apos;log4js&apos;);var log_config = require(&apos;../config/log_config&apos;);//加载配置文件log4js.configure(log_config);//日志报错的内容var logUtil = &#123;&#125;;var errorLogger = log4js.getLogger(&apos;errorLog&apos;);//封装错误日志logUtil.logError = function (ctx, error, resTime) &#123; if (ctx &amp;&amp; error) &#123; errorLogger.error(formatError(ctx, error, resTime)); &#125;&#125;;//格式化错误日志var formatError = function (ctx, err, resTime) &#123; var logText = new String(); //错误信息开始 logText += &quot;\n&quot; + &quot;*************** error log start ***************&quot; + &quot;\n&quot;; //添加请求日志 logText += formatReqLog(ctx.request, resTime); //错误名称 logText += &quot;err name: &quot; + err.name + &quot;\n&quot;; //错误信息 logText += &quot;err message: &quot; + err.message + &quot;\n&quot;; //错误详情 logText += &quot;err stack: &quot; + err.stack + &quot;\n&quot;; //错误信息结束 logText += &quot;*************** error log end ***************&quot; + &quot;\n&quot;; return logText;&#125;;module.exports = logUtil; 在index文件中添加引用： 123456789101112131415161718192021const logUtil = require(&apos;./middlewares/log_util&apos;); // 记录日志......// 日志接口调用信息日志输出app.use(async (ctx, next) =&gt; &#123; //响应开始时间 const start = new Date(); //响应间隔时间 var ms; try &#123; //开始进入到下一个中间件 await next(); ms = new Date() - start; //记录响应日志 logUtil.logResponse(ctx, ms); &#125; catch (error) &#123; ms = new Date() - start; //记录异常日志 logUtil.logError(ctx, error, ms); &#125;&#125;); 3. 保存日志的文件这个文件手动添加太麻烦，我们可以直接用代码判断他存不存在，不存在直接新建（可以写在 log_config.js中） 1234567891011121314151617181920212223242526272829var fs = require(&apos;fs&apos;);/** * 确定目录是否存在，如果不存在则创建目录 */var confirmPath = function(pathStr) &#123; if(!fs.existsSync(pathStr))&#123; fs.mkdirSync(pathStr); console.log(&apos;createPath: &apos; + pathStr); &#125;&#125;/** * 初始化log相关目录 */var initLogPath = function()&#123; //创建log的根目录&apos;logs&apos; if(baseLogPath)&#123; confirmPath(baseLogPath) //根据不同的logType创建不同的文件目录 //log4js2.0的appenders是个对象，length无法判断直接长度 let appendersArr = Object.keys(log_config_obj.appenders); for(var i = 0, len = appendersArr.length; i &lt; len; i++)&#123; if(log_config_obj.appenders[appendersArr[i]].path)&#123; confirmPath(baseLogPath + log_config_obj.appenders[appendersArr[i]].path); &#125; &#125; &#125;&#125;initLogPath(); 现在运行就可以看到生成的logs目录以及日志记录文件啦！]]></content>
      <categories>
        <category>koa2</category>
      </categories>
      <tags>
        <tag>koa2</tag>
        <tag>后台日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过周报系统的登录学到的session和cookie]]></title>
    <url>%2F2018%2F04%2F15%2F%E9%80%9A%E8%BF%87%E5%91%A8%E6%8A%A5%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%99%BB%E5%BD%95%E5%AD%A6%E5%88%B0%E7%9A%84session%E5%92%8Ccookie%2F</url>
    <content type="text"><![CDATA[关于session和cookie基础介绍：session和cookie关系session是基于cookie实现的,session在被创建后,会生成一个唯一的sessionid返回给浏览器， 并保存在浏览器的cookie中,接下来客户再次调用服务端接口，服务器便会从客户端发送过来的cookie中查找name为sessionid的cookie是否存在,若是存在则通过该cookie的值来找到用户之前创建的session,若是不存在则创建一个新的session。 然而保存sessionId的cookie默认是会话级别的,是保存在浏览器的内存中的,当浏览器关闭时这个cookie也就消失了,所以再次打开一个新的浏览器由于这个时候并不存在名为sessionid的cookie,所以服务器便会创建一个新的session,但是原来的session还是存在的!也就是说 这时候服务器中一共存在两个session。 设置cookie的过期时间，必须关闭浏览器的随浏览器关闭而清除cookie的功能 cookie过期时间但是cookie也可以设置过期时间，不设置的话默认随着浏览器的关闭而清楚，因为未设置过期时间的cookie只能存在浏览器，设置过期时间的话就会存到本地硬盘上，浏览器关闭就不影响cookie（除非到了过期时间它自动清除），这个时候当浏览器再次打开，会从本地读取cookie，发送给服务端，在重复执行过程一。这个可用于一定时间内免用户登录的需求等 session过期时间session也有过期时间，默认为20分钟，20分钟后自动清除session。当session过期后，浏览器发送过来的cookie就无法在服务器端找到对应的session，因为session已经不存在，此时需要重新登录并设置session，重复过程一 结合具体项目代码谈谈：项目具体代码在周报登录中，使用的是koa-session-minimal和koa-mysql-session中间件，先贴代码：1234567891011121314151617181920212223242526272829303132333435363738const config = require(&apos;../config/default&apos;); // 数据库相关的配置文件const session = require(&apos;koa-session-minimal&apos;); // 处理数据库中间件const MysqlStore = require(&apos;koa-mysql-session&apos;); // 处理数据库中间件let createSession = (app) =&gt; &#123; // session数据库存储配置 const sessionMysqlConfig= &#123; user: config.database.USERNAME, password: config.database.PASSWORD, database: config.database.DATABASE, host: config.database.HOST, port: config.database.PORT &#125;; // session/cookie 属性配置 let sessionOptions = &#123; key: &apos;session-id&apos;, // cookie 中存储 session-id 时的键名, 默认为 koa:sess cookie: &#123; // 与 cookie 相关的配置 domain: &apos;&apos;, // 写 cookie 所在的域名 path: &apos;/&apos;, // 写 cookie 所在的路径 maxAge: 1000 * 60 * 10, // cookie 有效时长(单位：ms) httpOnly: true, // 是否只用于 http 请求中获取 overwrite: true // 是否允许重写 &#125;, store: new MysqlStore(sessionMysqlConfig) &#125;; app.use(async (ctx, next) =&gt; &#123; // 获取hostname，设置cookie的domain属性值 sessionOptions.cookie.domain = ctx.request.hostname; await next(); &#125;); app.use(session(sessionOptions));&#125;;module.exports = createSession; 在每次用户登录的时候，都会设置session：123ctx.session = &#123; userId: &apos;???&apos;&#125;; 存储session的时候就会通过这个文件中的配置，给设置的数据库中添加一个名字为_mysql_session_store的表并存储下面的数据：1id: &apos;session-id：自动生成的序列号&apos;，expires： &apos;session设置的过期时间&apos;,data: &apos;登录时存储的值&apos; 同时向前端返回值为session-id的cookie，并存在客户端，每次请求时都会将cookie同时发送给服务端，我们只在每次请求时判断ctx.session.userId是否存在，能取到则是sessio存在且未过期，则可以继续执行相应操作 注意： 其实在取值时中间件已经帮我们做了很多工作：进行这一步时候中间件先是通过客户端发过来的cookie对应的值去找数据库中对应的数据，如果存在且未过期的话则返回对应的data，即本文中的userId 关于这个中间件中session和cookie的过期时间：中间件中默认session过期时间为一天，cookie是随着浏览器关闭而关闭，只有在maxAge值大于0时，cookie和session的过期时间保持一致为maxAge的值。]]></content>
      <categories>
        <category>koa2</category>
      </categories>
      <tags>
        <tag>session和cookie</tag>
        <tag>用户免登陆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql学习笔记]]></title>
    <url>%2F2018%2F04%2F10%2Fmysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基本了解：mysql数据库为关系型数据库，个关系型数据库由一个或数个表格组成，表格中肯定有键（键(key): 表中用来识别某个特定的人物的方法, 键的值在当前列中具有唯一性。） 登录mysql（记得配置环境变量） 管理员模式打开cmd 启动服务net start mysql 登录mysql -u root -p，回车之后根据提示输入密码 建表等操作 关闭服务net start mysql 注意，可能会报错： 123C:\AppServ\MySQL&gt; mysql -u root -p Enter password: ERROR 1045 (28000): Access denied for user &apos;root&apos;@&apos;localhost&apos; (using password: YES 解决方法如下： 编辑mysql配置文件my.ini（在mysql的安装目录下，我的在D:\Program Files\MySQL\MySQL Server 5.0\my.ini），在[mysqld]这个条目下加入 skip-grant-tables 保存退出后重启mysql 点击“开始”-&gt;“运行”(快捷键Win+R)。 停止：输入 net stop mysql 启动：输入 net start mysql 这时候在cmd里面输入mysql -u root -p就可以不用密码登录了，出现 password：的时候直接回车可以进入，不会出现ERROR 1045 (28000)，但很多操作都会受限制，因为我们不能grant（没有权限）。 继续按下面的流程走： 进入mysql数据库： 12mysql&gt; use mysql; Database changed 给root用户设置新密码： 123mysql&gt; update mysql.user set authentication_string=password(&quot;新密码&quot;) where user=&quot;root&quot;; Query OK, 1 rows affected (0.01 sec) Rows matched: 1 Changed: 1 Warnings: 0 刷新数据库 12mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) 退出mysql： 12mysql&gt; quit; Bye 改好之后，再修改一下my.ini这个文件，把我们刚才加入的 “skip-grant-tables”这行删除，保存退出再重启mysql就可以了。 关于可视化工具HeidiSql的使用 访问本机时候mysql时候，ip可以使本机ip或者默认的127.0.0.1,用户名为mysql之前设置的用户名，密码也是自己设置的，我的默认为root，** 配置好后直接打开即可 创建库才能创建表12345678-- 创建一个名为 samp_db 的数据库，数据库字符编码指定为 gbkcreate database samp_db character set gbk;drop database samp_db; -- 删除 库名为samp_db的库show databases; -- 显示数据库列表。use samp_db; -- 选择创建的数据库samp_dbshow tables; -- 显示samp_db下面所有的表名字describe 表名; -- 显示数据表的结构delete from 表名; -- 清空表中记录 创建表123456789101112CREATE TABLE `user_accounts` ( `id` int(100) unsigned NOT NULL AUTO_INCREMENT primary key, `password` varchar(32) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;用户密码&apos;, `reset_password` tinyint(32) NOT NULL DEFAULT 0 COMMENT &apos;用户类型：0－不需要重置密码；1-需要重置密码&apos;, `mobile` varchar(20) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;手机&apos;, `create_at` timestamp(6) NOT NULL DEFAULT CURRENT_TIMESTAMP(6), `update_at` timestamp(6) NOT NULL DEFAULT CURRENT_TIMESTAMP(6) ON UPDATE CURRENT_TIMESTAMP(6), -- 创建唯一索引，不允许重复 UNIQUE INDEX idx_user_mobile(`mobile`))ENGINE=InnoDB DEFAULT CHARSET=utf8COMMENT=&apos;用户表信息&apos;; 数据类型的属性解释： 123456789101112131415NULL：数据列可包含NULL值；NOT NULL：数据列不允许包含NULL值；DEFAULT：默认值；PRIMARY：KEY 主键；AUTO_INCREMENT：自动递增，适用于整数类型；UNSIGNED：是指数值类型只能为正数；CHARACTER SET name：指定一个字符集；COMMENT：对表或者字段说明； 增删改查select123SELECT 语句用于从表中选取数据。 语法：SELECT 列名称 FROM 表名称 语法：SELECT * FROM 表名称 update12Update 语句用于修改表中的数据。 语法：UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值 insert123INSERT INTO 语句用于向表格中插入新的行。 语法：INSERT INTO 表名称 VALUES (值1, 值2,....) 语法：INSERT INTO 表名称 (列1, 列2,...) VALUES (值1, 值2,....) delete12DELETE 语句用于删除表中的行。 语法：DELETE FROM 表名称 WHERE 列名称 = 值 参考： https://segmentfault.com/a/1190000006876419]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Express&&MongoDb&&vue全家桶&&axios搭建个人博客笔记(三)]]></title>
    <url>%2F2018%2F04%2F01%2F%E5%9F%BA%E4%BA%8EExpress-MongoDb-vue%E5%85%A8%E5%AE%B6%E6%A1%B6-axios%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%AC%94%E8%AE%B0-%E4%B8%89%2F</url>
    <content type="text"><![CDATA[项目前端代码地址：https://github.com/fighting123/my_blog_FE 项目后台代码地址：https://github.com/fighting123/my_blog_BE 关于主页点击跳转到详情页无法获取id问题点击具体的文章时，无法获取到此文章的id，除非分析Dom结构，但是Vue是基于数据驱动的，应对充分尊重此点。所以在v-for生成文章列表的时候添加点击事件，将本身点击文章标题触发的事件放到整个组件上，这个时候是可以轻松获取的具体点击哪个文章的id的12345&lt;el-main&gt; &lt;div v-for=&quot;(message, index) in messageList&quot; :key=&quot;index&quot; @click.once=&quot;detailHandle(message._id)&quot;&gt; &lt;Posts :message=&quot;message&quot; @getOnePost=&quot;showOnePost&quot; @getPostList=&quot;showList&quot;&gt;&lt;/Posts&gt; &lt;/div&gt; &lt;/el-main&gt; 但是这个要注意得事子组件posts内元素的所有点击事件要加上事件修饰符.stop防止事件冒泡触发详情事件。 对于详情页和主页的复用问题： 详情页和主页复用一个页面，但是刷新是总是存在头像不对应或者文章文章标题可以二次点击等各种问题，之后使用个比较笨的方法，在posts组件中路由变化时都强制刷新页面，这样数据可以重新渲染++(忽然想到vue的计算属性computed，这样既解决了img的src不能自动计算而不更新图片的问题，而且不用强制刷新页面)++ 12345computed: &#123; imgSrc: function () &#123; return `/api/image/$&#123;this.message.author.avatar&#125;` &#125; &#125;, 为了详情页面重新刷新时仍停留在详情页面并且还是显示之前的文章页，可以这么处理：在跳转到详情页时将此文章的id加载路由中，这样页面刷新就可通过this.$route.params.id获取他的id了]]></content>
      <categories>
        <category>个人项目笔记</category>
      </categories>
      <tags>
        <tag>博客前后台</tag>
        <tag>express个人博客</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Express&&MongoDb&&vue全家桶&&axios搭建个人博客笔记(二)]]></title>
    <url>%2F2018%2F03%2F28%2F%E5%9F%BA%E4%BA%8EExpress-MongoDb-vue%E5%85%A8%E5%AE%B6%E6%A1%B6-axios%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%AC%94%E8%AE%B0-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[项目前端代码地址：https://github.com/fighting123/my_blog_FE 项目后台代码地址：https://github.com/fighting123/my_blog_BE 花了好几天时间终于解决了这个可能在别人看来十分简单的问题，毕竟第一次上手后台，很多东西还是不懂得，加油！先来一个参考链接：https://www.cnblogs.com/thingk/archive/2013/11/25/3434032.html 首先是注册页面的图片上传用的是element的上传组件，action参数是图片上传的地址，本身是想和其他用户注册时的其他参数一齐上传，但是这是有问题的，图片上传应该是需要一个特殊的接口，将图片保存到服务器，然后将这个图片的地址保存到数据库中，每次需要时通过数据库的地址查找对应的图片，代码如下： 前端代码：123456789101112 &lt;el-upload ref=&quot;upload&quot; class=&quot;avatar-uploader&quot; action=&quot;http://localhost:8080/api/signup/image&quot; name=&quot;avatar&quot; :show-file-list=&quot;false&quot; :auto-upload=&quot;false&quot; :on-change=&quot;handleAvatarSuccess&quot; :before-upload=&quot;beforeAvatarUpload&quot;&gt; &lt;img v-if=&quot;imageUrl&quot; :src=&quot;imageUrl&quot; class=&quot;avatar&quot;&gt; &lt;i v-else class=&quot;el-icon-plus avatar-uploader-icon&quot;&gt;&lt;/i&gt;&lt;/el-upload&gt; 关于imgUrl： 1234handleAvatarSuccess (res, file) &#123; this.imageUrl = URL.createObjectURL(file[0].raw) this.signUpForm.avatar = file[0]&#125;, 需要在注册提交事件中触发： 1vm.$refs[&apos;upload&apos;].submit() 后台代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 先把图片存储起来router.post(&apos;/image&apos;, function (req, res, next) &#123; res.send(&#123;status: &apos;success&apos;&#125;) console.log(req.fields.avatar)&#125;)// 注册接口router.post(&apos;/&apos;, checkNotLogin, function (req, res, next) &#123; // 读取image文件夹取files第一个为刚才注册所用的图片 fs.readdir(&apos;public/image&apos;, function (err, files) &#123; if (err) &#123; console.log(err); return; &#125; // var imagePathName = &apos;&apos; // imagePathName = path.join(path.resolve(__dirname, &apos;..&apos;), &apos;/public/image/&apos;, files[0]) var name = req.fields.name var gender = req.fields.gender var bio = req.fields.bio var password = req.fields.password var repassword = req.fields.repassword // 明文密码加密 password = sha1(password); // 待写入数据库的用户信息 var user = &#123; name: name, gender: gender, bio: bio, avatar: files[0], password: password, repassword: repassword &#125; // 用户信息写入数据库 UserModel.create(user) .then(function (result) &#123; // 此 user 是插入 mongodb 后的值，包含 _id user = result.ops[0] // 删除密码这种敏感信息，将用户信息存入 session delete user.password req.session.user = user res.send(&#123;status: &apos;success&apos;, message: &apos;注册成功&apos;&#125;) &#125;) .catch(function (e) &#123; // 注册失败，异步删除上传的头像 // fs.unlink(imagePathName) // 用户名被占用则跳回注册页，而不是错误页 if (e.errmsg.match(&apos;duplicate key&apos;)) &#123; // req.flash(&apos;error&apos;, &apos;用户名已被占用&apos;) res.send(&#123;status: &apos;error&apos;, message: &apos;用户名已被占用&apos;&#125;) &#125; // next(e) &#125;) &#125;)&#125;) 在后台的index.js文件下添加中间件： 12345// 处理表单及文件上传的中间件app.use(require(&apos;express-formidable&apos;)(&#123; uploadDir: path.join(__dirname, &apos;public/image&apos;), // 上传文件目录 keepExtensions: true // 保留后缀&#125;)) 第二部分是部分需要显示图片的页面前端代码： 在登录时将imgUrl地址存起来，以方便后面页面请求需要： 1localStorage.set(&apos;imgUrl&apos;, res.data.imgUrl, res.data.expTime) 需要获取图片的页面：1&lt;img :src=&quot;imgSrc&quot; alt=&quot;&quot;&gt; 图片src设置为请求的接口：123created() &#123; this.imgSrc = `/api/image/$&#123;localStorage.get(&apos;imgUrl&apos;)&#125;`&#125; 后台代码： 添加路由： 1234567891011121314151617181920module.exports = function (app) &#123; app.get(&apos;/api/image/:url&apos;, function (req, res) &#123; // 获取到图片的在后台的完整路径，否则拿不到图片 var imagePathName = &apos;&apos; imagePathName = path.join(path.resolve(__dirname, &apos;..&apos;), &apos;/public/image/&apos;, req.params.url) // 读取图片 fs.readFile(imagePathName, &apos;binary&apos;, function (err, data) &#123; if (err) &#123; res.writeHead(500,&#123;&quot;Content-Type&quot;:&quot;text/plain&quot;&#125;); res.write(error+&quot;\n&quot;); res.end(); &#125; else &#123; res.writeHead(200,&#123;&quot;Content-Type&quot;:&quot;image/png&quot;&#125;); // 不能用send，否则会浏览器报错：504 (Gateway Timeout) // res.send(data, &quot;binary&quot;); res.end(data, &apos;binary&apos;); &#125; &#125;) &#125;) &#125;]]></content>
      <categories>
        <category>个人项目笔记</category>
      </categories>
      <tags>
        <tag>博客前后台</tag>
        <tag>express个人博客</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Express&&MongoDb&&vue全家桶&&axios搭建个人博客笔记(一)]]></title>
    <url>%2F2018%2F03%2F21%2F%E5%9F%BA%E4%BA%8EExpress-MongoDb-vue%E5%85%A8%E5%AE%B6%E6%A1%B6-axios%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E7%AC%94%E8%AE%B0-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[项目前端代码地址：https://github.com/fighting123/my_blog_FE 项目后台代码地址：https://github.com/fighting123/my_blog_BE 1.前后端分离产生的跨域问题：解决方法一：在webpack（config/index.js）的修改为： 123456789proxyTable: &#123; &apos;/api&apos;: &#123; target: &apos;http://192.168.212.23:9898&apos;, changeOrigin: true, pathRewrite: &#123; &apos;^/api&apos;: &apos;/&apos; &#125; &#125;&#125; 相应的globalOptions的baseUrl也设置为:1baseURL: &apos;/api&apos;, 整个设置意思为：每次遇到/api的访问请求时，就会在proxyTable中自动代理到target的值中（也就是示例中的http://192.168.212.23:9898），并且在发起请求中根据pathRewrite的设置，修改请求路径（示例中是将所有的/api替换为/，也就是直接请求后台，避免后台要给每个接口添加/api字段） 解决方法二：使用koa2-cors中间件： 123456789101112131415161718192021222324252627282930313233343536var koa = require(&apos;koa&apos;);var app = new koa();var router = require(&apos;koa-router&apos;)();// CORS是一个W3C标准，全称是&quot;跨域资源共享&quot;（Cross-origin resource sharing）。// 下面以koa2-cors为例，const cors = require(&apos;koa2-cors&apos;);// 具体参数我们在后面进行解释app.use(cors(&#123; origin: function (ctx) &#123; if (ctx.url === &apos;/test&apos;) &#123; return &quot;*&quot;; // 允许来自所有域名请求 &#125; return &apos;http://localhost:8080&apos;; / 这样就能只允许 http://localhost:8080 这个域名的请求了 &#125;, exposeHeaders: [&apos;WWW-Authenticate&apos;, &apos;Server-Authorization&apos;], // 该字段可选，用来指定本次预检请求的有效期，单位为秒。 // 当请求方法是PUT或DELETE等特殊方法或者Content-Type字段的类型是application/json时，服务器会提前发送一次请求进行验证 // 下面的的设置只本次验证的有效时间，即在该时间段内服务端可以不用进行验证 maxAge: 5, // 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。 // 当设置成允许请求携带cookie时，需要保证&quot;Access-Control-Allow-Origin&quot;是服务器有的域名，而不能是&quot;*&quot;; credentials: true, allowMethods: [&apos;GET&apos;, &apos;POST&apos;, &apos;DELETE&apos;], allowHeaders: [&apos;Content-Type&apos;, &apos;Authorization&apos;, &apos;Accept&apos;],&#125;))router.post(&apos;/&apos;, async function (ctx) &#123; ctx.body = &apos;恭喜 __小简__ 你成功登陆了&apos;&#125;);app .use(router.routes()) .use(router.allowedMethods());app.listen(3000); *注意：如果前端用的axios，并且headers设置的代码如下（这时浏览器会先以options的方式请求后台，成功才会继续使用get，post请求接口，如果后台不增加设置allowMethods和allowHeaders字段，options这一步就会产生跨域问题，导致后续无法请求成功）：**12345678const globalOptions = &#123; withCredentials: true, baseURL: &apos;http://192.168.212.23:9898&apos;, timeout: 60000, headers: &#123; &apos;axios-header&apos;: &apos;axios&apos; &#125;&#125;; 那么后台应该对应的添加字段，代码如下：12345&#123; ...... allowMethods: [&apos;GET&apos;, &apos;POST&apos;, &apos;DELETE&apos;, &apos;OPTIONS&apos;], allowHeaders: [&apos;Content-Type&apos;, &apos;Authorization&apos;, &apos;Accept&apos;, &apos;axios-header&apos;]&#125; 再具体的相关解释参考node.js应答跨域请求实现（以koa2-cors为例） 解决方法三：其他方法参考前端跨域问题 2.请求到后304在请求上添加事件戳(plugins/index.js) 123456789101112131415161718192021222324import axios from &apos;axios&apos;function convertURL (url) &#123; // 获取时间戳 let timstamp = (new Date()).valueOf() // 将时间戳信息拼接到url上 if (url.indexOf(&apos;?&apos;) &gt;= 0) &#123; url = url + &apos;&amp;t=&apos; + timstamp &#125; else &#123; url = url + &apos;?t=&apos; + timstamp &#125; return url&#125;export default &#123; post (url, data, config) &#123; return axios.post(convertURL(url), data, config).then((res) =&gt; &#123; return res &#125;) &#125;, get (url, params, config) &#123; return axios.get(convertURL(url), config).then((res) =&gt; &#123; return res &#125;) &#125;&#125; 3.对于未登录与登录后看到页面显示不同的问题用vuex控制，store存储一个loginStatus的变量，默认false，点击登录则为true，点击登出变为false 4.对于路由跳转问题登录之后不能在进入登录页，未登录不能发表文章，删除文章等功能的控制，可以用router.beforeEach来判断_id是否存在，这个_id是每次登录成功后后台返回的用户的id，每次登出时候将其清除12345678910111213141516router.beforeEach((to, from, next) =&gt; &#123; // 如果localStorage没有_id则表示未登录，强制跳转到登录页 if (!localStorage.getItem(&apos;_id&apos;)) &#123; if (to.path !== &apos;/signUp&apos; &amp;&amp; to.path !== &apos;/signIn&apos;) &#123; next(&apos;/signIn&apos;) &#125; else &#123; next() &#125; &#125; else &#123; if (to.path === &apos;/signIn&apos;) &#123; next(&apos;/&apos;) &#125; else &#123; next() &#125; &#125;&#125;) 5.关于session在每次登录请求时候，后台返回过期时间，前台根据这个时间来设置localstorage的过期时间（localstorage本身不会失效，没有过期时间，因此需要手动设置），返回的过期时间需要和config中设置的maxAge的session过期时间一致]]></content>
      <categories>
        <category>个人项目笔记</category>
      </categories>
      <tags>
        <tag>博客前后台</tag>
        <tag>express个人博客</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack初识]]></title>
    <url>%2F2018%2F03%2F19%2Fwebpack%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[安装webpack123456789//全局安装npm install -g webpack//安装到项目目录npm install --save-dev webpack//全局安装（同时需要安装webpack-cli，否则提示The CLI moved into a separate package: webpack-cli.）npm install webpack-cli -g//安装到项目目录npm install --save-dev webpack-cli 区别：安装到项目目录运行时需要加上在node_modules中的地址，如：node_modules/.bin/webpack 使用webpack前的准备工作创建如图所示的文件： 首先用npm init生成package.json文件，然后创建文件，public是存放浏览器读取的文件，app是存放未打包前的模块文件 Greeter.js模块: 1234567const greeter = () =&gt; &#123; let greet = document.createElement(&apos;div&apos;) greet.textContent = &apos;hello&apos; return greet&#125;module.exports = greeter() main.js引入模块的文件： 12let greeter = require(&apos;./Greeter&apos;)document.querySelector(&quot;#body&quot;).appendChild(greeter) index.html主页面: 12345678910111213&lt;!doctype html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0&quot;&gt; &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt; &lt;title&gt;webpack_sample_practice&lt;/title&gt;&lt;/head&gt;&lt;body id=&quot;body&quot;&gt;&lt;/body&gt;&lt;script src=&quot;bundle.js&quot;&gt;&lt;/script&gt;&lt;/html&gt; bundle.js打包后存储的文件（index.html引入的文件） （一）使用命启动令webpack1webpack app/main.js public/bundle.js // webpack 入口文件 打包后文件 这时会提示warning，这是因为没有设置mode,所以需要：123webpack app/main.js public/bundle.js --mode development（未压缩）// 或者webpack app/main.js public/bundle.js --mode production（压缩过） 为方便起见，我们将这两句命令放入package.json文件中：1234&quot;scripts&quot;: &#123; &quot;dev&quot;: &quot;webpack app/main.js public/bundle.js --mode development&quot;,//（未压缩） &quot;build&quot;: &quot;webpack app/main.js public/bundle.js --mode production&quot; //（压缩过） &#125;, 这样，在每次启动是只需要输入npm run dev 或者npm run build 最后，打开浏览器页面就可以访问啦！ （二）通过配置webpack.config.js来使用webpack我们也可以通过更加方便简洁的方式使用webpack，这样也比较不容易出错。 在主目录新建webpack.config.js配置文,先简单的只配置下入口和出口文件目录: 1234567module.exports = &#123; entry: __dirname + &quot;/app/main.js&quot;,//已多次提及的唯一入口文件 output: &#123; path: __dirname + &quot;/public&quot;,//打包后的文件存放的地方 filename: &quot;bundle.js&quot;//打包后输出文件的文件名 &#125;&#125; 同意为方便我们配置package.json文件： 1234&quot;scripts&quot;: &#123; &quot;dev&quot;: &quot;webpack --mode development&quot;, &quot;build&quot;: &quot;webpack --mode production&quot; &#125;, 输入npm run dev 或者 npm run build同样可以正常启动啦！ 参考：https://www.jianshu.com/p/42e11515c10f]]></content>
      <categories>
        <category>webpack</category>
      </categories>
      <tags>
        <tag>打包</tag>
        <tag>Webpack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo基本操作]]></title>
    <url>%2F2018%2F03%2F15%2Fhexo%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[创建文章1$ hexo new "My New Post" More info: Writing 本地运行1$ hexo server More info: Server 编译1$ hexo generate More info: Generating 发布1$ hexo deploy 同步项目源文件到Github123456789// 添加源文件git add .// git提交git commit -m &quot;&quot;// 先拉原来Github分支上的源文件到本地，进行合并// 分支名后面的“--allow-unrelated-histories”是为了弹出“fatal: refusing to merge unrelated histories.”的错误git pull origin 分支名 --allow-unrelated-histories// 比较解决前后版本冲突后，push源文件到Github的分支git push origin 分支名]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo搭建简记]]></title>
    <url>%2F2018%2F03%2F14%2Fhexo%E6%90%AD%E5%BB%BA%E7%AE%80%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[博客搭建步骤简记网上基于hexo搭建博客的教程非常多，本文只是结合自己博客的需求对网上的文章进行了过滤和总结，大致可以囊括常用的所有功能 按照教程配好基础的博客并修改个人信息，可参考： https://www.jianshu.com/p/d49e4684e62b https://hexo.io/zh-cn/docs/configuration.html https://www.jianshu.com/p/9f0e90cc32c2 https://www.jianshu.com/p/f054333ac9e6(酷炫效果的总结) 更换主题为next（参考1） 添加分类。标签功能（参考1） 添加搜索功能，next官网上有很多第三方搜索服务，我用的是Local Search，具体可以按照教程来 添加统计，同上，我用的LeanCloud和不蒜子 添加评论功能，DISQUS官网进不去，所以我用的是LeanCloud 首页文章以摘要形式显示：将主题设置的auto_excerpt的enable为true 设置首页文章显示篇数(参考：http://www.jeyzhang.com/next-theme-personal-settings.html) 设置404页面,用的是腾讯公益404页面(直接在站点的source目录下新建404.html) 设置头像(两张存储位置对应不用的文件夹名称，需要注意，然后将主题的avatar的注释放开并且填写对应位置) 设置icon，在阿里妈妈矢量库寻找合适图像，下载16 16和32 32的png格式，将next主题下的favicon图片更换掉 解决github+Hexo的博客多终端同步问题(https://www.jianshu.com/p/6fb0b287f950) 剩下的各种详情都参考第一条（有时间在统一整理） 添加动态背景（https://huur.cn/res/413.html）注意：这篇文章的写法有问题，更正之后可以运行，代码如下： 123&#123;% if (theme.canvas_nest) %&#125; &lt;script type=&quot;text/javascript&quot; color=&quot;0,0,0&quot; opacity=&apos;0.4&apos; zIndex=&quot;-2&quot; count=&quot;66&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 并把themes/next/_config.yml文件下的两个canvas_nest都设置为true即可 社交连接等icon都是出自fontawesome的官网https://fontawesome.com/?from=io，在这里寻找合适的icon在config里设置即可 添加点击出现小心心（https://asdfv1929.github.io/2018/05/25/baidu-share/）,效果没有透明度不美观，我在源码中将透明度改成了0.8 之前文章的图片都是存放在七牛云上，最近七牛云的测试域名全部回收，还好我的图片有备份（坑），索性直接新建个git仓库来专门存放文章的图片（省的在糟心），每个图片点击Download就可以获取链接了最后的最后，要注意得是： 发布文章要用gitbash，用终端会报错 发布文章完成后记得上传到git的hexo分支，保存源代码]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
</search>
